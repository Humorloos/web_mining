{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70667777-0f0c-4860-9b6c-b9fa5a04bb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d59f4c78-a1d4-45cd-a9dc-3c5df6043fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4267de6-d7f5-444e-9b9b-205f26c7911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import LSTM, Activation, Dropout, Dense, Input, CuDNNLSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b524ed-98e9-4e78-9817-aa41a8b5e8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\harit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a4d03b-3f0a-436e-952f-f91118c6a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetDF = pd.read_csv(\"premade_datasets/training_dataset_non_lemmatized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93234e1d-9280-4551-a0c2-ecd1125b9244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>prep_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Now I canâ€™t I see itðŸ˜­ðŸ˜­ https://t.co/8ZPKtJ2SLd</td>\n",
       "      <td>now i i see it URL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No this is a REAL FEAR ðŸ˜­ðŸ˜­ðŸ˜­ https://t.co/68HkUu...</td>\n",
       "      <td>no this is a real fear URL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@kwadwosheldon Grown up paa ow ðŸ˜“</td>\n",
       "      <td>USERNAME grown up paa ow</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>God I hate being responsible sometimes. My fam...</td>\n",
       "      <td>god i hate being responsible sometimes my fami...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@LUXMINAJJ @BenjaminEnfield peaches Like it ðŸ˜­</td>\n",
       "      <td>USERNAME USERNAME peaches like it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "0     Now I canâ€™t I see itðŸ˜­ðŸ˜­ https://t.co/8ZPKtJ2SLd   \n",
       "1  No this is a REAL FEAR ðŸ˜­ðŸ˜­ðŸ˜­ https://t.co/68HkUu...   \n",
       "2                   @kwadwosheldon Grown up paa ow ðŸ˜“   \n",
       "3  God I hate being responsible sometimes. My fam...   \n",
       "4      @LUXMINAJJ @BenjaminEnfield peaches Like it ðŸ˜­   \n",
       "\n",
       "                                           prep_text  sentiment  \n",
       "0                                 now i i see it URL          0  \n",
       "1                         no this is a real fear URL          0  \n",
       "2                           USERNAME grown up paa ow          0  \n",
       "3  god i hate being responsible sometimes my fami...          0  \n",
       "4                  USERNAME USERNAME peaches like it          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aa7b4c6-eaa9-4354-b702-321eae83e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input= tweetDF['prep_text']\n",
    "y_input= tweetDF['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eebe8b6-bc8d-46f3-a017-18aaebbbb8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postProcessing(tweet):\n",
    "    text = tweet\n",
    "    # remove non letters\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    # tokenize\n",
    "    words = text.split()\n",
    "    # remove stopwords\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "    \n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "819d1116-0938-46dd-8ad7-588add08b6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                    see URL\n",
       "1                                              real fear URL\n",
       "2                                      USERNAME grown paa ow\n",
       "3          god hate responsible sometimes family going un...\n",
       "4                             USERNAME USERNAME peaches like\n",
       "                                 ...                        \n",
       "2169656                                             new gens\n",
       "2169657                                   USERNAME fuck yeah\n",
       "2169658    USERNAME bts comeback 10 de junho btsbarmy com...\n",
       "2169659    mental health awareness month join us may cont...\n",
       "2169660                                             USERNAME\n",
       "Name: prep_text, Length: 2169661, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_input.apply(postProcessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "814ecc76-c25b-404e-9484-5bc692da4004",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_input, y_input, test_size=0.20, random_state=42, stratify=y_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f66e5323-e85e-4841-b303-e7660cd82088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LSTMEmbedding import LSTMEmbedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6921b7a-3f0e-4275-b5d1-c1f4516b4a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LSTMEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "192e639c-0322-4b11-8d51-404eae5cc462",
   "metadata": {},
   "outputs": [],
   "source": [
    "le.initialize_tokenizer(8000, 30)\n",
    "le.fit_tokenizer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87446fb0-30a2-438e-8a4d-563f702b0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "le.read_glove_vector('glove.twitter.27B.200d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfd9b56f-6d8b-48d9-b951-319b16b7ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer = le.create_embedding_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb984de5-aad3-40b6-b6dc-148c67ee9632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ec4dfe7-f844-481a-a21d-aced4e65aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = le.text_to_sequences(X_train)\n",
    "X_val_indices = le.text_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1c60212-6ecf-4666-a504-cadb73ee117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = .001\n",
    "hidden_nodes = [150, 100,  50] \n",
    "max_epochs = 100\n",
    "patience = 5\n",
    "batch_size = 128\n",
    "dropout_rate = 0.6\n",
    "bidirectional = True\n",
    "shape =X_train_indices.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36ff7472-0ae4-411d-a622-7a908820118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model, lr, loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam'):\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr) if optimizer=='adam' else tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7516381-cb5a-4d5c-b846-d2950e20176a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 30, 200)           61096200  \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 30, 300)          422400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 30, 300)           0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 30, 200)          321600    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 30, 200)           0         \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 100)              100800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,941,101\n",
      "Trainable params: 844,901\n",
      "Non-trainable params: 61,096,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = le.build_model(hidden_nodes, input_shape=shape, embedding_layer=emb_layer,bidirectional=True, dropout_rate=dropout_rate)\n",
    "model = compile_model(model, lr)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8855dfff-6f2b-4df2-9cb7-97f5076973cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13561/13561 [==============================] - 450s 33ms/step - loss: 0.5607 - accuracy: 0.7029 - val_loss: 0.5464 - val_accuracy: 0.7147\n",
      "Epoch 2/100\n",
      "13561/13561 [==============================] - 444s 33ms/step - loss: 0.5381 - accuracy: 0.7201 - val_loss: 0.5394 - val_accuracy: 0.7197\n",
      "Epoch 3/100\n",
      "13561/13561 [==============================] - 445s 33ms/step - loss: 0.5261 - accuracy: 0.7286 - val_loss: 0.5380 - val_accuracy: 0.7212\n",
      "Epoch 4/100\n",
      "13561/13561 [==============================] - 445s 33ms/step - loss: 0.5156 - accuracy: 0.7360 - val_loss: 0.5401 - val_accuracy: 0.7205\n",
      "Epoch 5/100\n",
      "13561/13561 [==============================] - 445s 33ms/step - loss: 0.5058 - accuracy: 0.7428 - val_loss: 0.5432 - val_accuracy: 0.7196\n",
      "Epoch 6/100\n",
      "13561/13561 [==============================] - 445s 33ms/step - loss: 0.4968 - accuracy: 0.7488 - val_loss: 0.5479 - val_accuracy: 0.7184\n",
      "Epoch 7/100\n",
      "13561/13561 [==============================] - 439s 32ms/step - loss: 0.4889 - accuracy: 0.7540 - val_loss: 0.5550 - val_accuracy: 0.7156\n",
      "Epoch 8/100\n",
      "13561/13561 [==============================] - 435s 32ms/step - loss: 0.4822 - accuracy: 0.7583 - val_loss: 0.5631 - val_accuracy: 0.7138\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)                    \n",
    "history = model.fit(X_train_indices, y_train, epochs=max_epochs, batch_size=batch_size, validation_data=(X_val_indices, y_val),\n",
    "                            shuffle=False, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5d92f52-4595-4aac-b6a3-90cc44c80f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaltweetDF = pd.read_csv(\"premade_datasets/evaluation_dataset_non_lemmatized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d7c617f8-5bdf-485c-8e0f-193352b43d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= EvaltweetDF['prep_text']\n",
    "y_test= EvaltweetDF['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "45ed9c51-3ebe-48cc-878d-5079a021050b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       USERNAME aww bad\n",
       "1                               bro tv break crunch time\n",
       "2              USERNAME bestie cry everyday like EMO URL\n",
       "3                             talking stop liking period\n",
       "4      USERNAME yes ending shocking devastating cared...\n",
       "                             ...                        \n",
       "194    USERNAME USERNAME thanks sabrina appreciate tw...\n",
       "195    USERNAME kai handle anything push everything g...\n",
       "196    always pleasure meeting legend virat bhai stil...\n",
       "197    long breathing manchester united always get fu...\n",
       "198                      USERNAME thank much support EMO\n",
       "Name: prep_text, Length: 199, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.apply(postProcessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "860654eb-715e-4b09-9a19-f52fc80e000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_indices = le.text_to_sequences(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ccc76f9-fa3e-4ee2-b945-759be270c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_indices)\n",
    "y_pred = np.around(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f9f7d05-8486-4042-b6c9-a385cd1868f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[90  9]\n",
      " [13 87]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89        99\n",
      "           1       0.91      0.87      0.89       100\n",
      "\n",
      "    accuracy                           0.89       199\n",
      "   macro avg       0.89      0.89      0.89       199\n",
      "weighted avg       0.89      0.89      0.89       199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7809659e-dc75-42d5-b582-389dbf0e8803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "19933f76-dac9-472a-b164-b63eebfee3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [pd.read_csv(path.join('reddit/final',x)) for x in os.listdir(\"reddit/final\") if path.isfile(path.join(\"reddit/final\",x))]\n",
    "reddit = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb2f1069-656c-450b-9622-fbe93f7c96e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= reddit['prep_text']\n",
    "y_test= reddit['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5de22033-e3c8-4328-90d0-33e9bc189c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      ukraine collects russian dead war rages multip...\n",
       "1      lawsuit claims bastrop county deputies torture...\n",
       "2      israeli police beat mourners murdered al jazee...\n",
       "3      us lawmakers decry israeli forces attacking fu...\n",
       "4      amelia baca baca family attorneys demand murde...\n",
       "                             ...                        \n",
       "104    underground facility hold soviet warship perfe...\n",
       "105    nostalgic survivors know love beautiful images...\n",
       "106    happy international womens wish women h w new ...\n",
       "107    one largest abandoned dive sites canada radioa...\n",
       "108    hailed heroes scottish gardeners rescued trio ...\n",
       "Name: prep_text, Length: 218, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.apply(postProcessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05baf274-d1d9-43bf-99df-7f0e29d6f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_indices = le.text_to_sequences(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7cb55df-fc6c-422e-bfcc-0098f672235a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_indices)\n",
    "y_pred = np.around(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "37584324-5249-4760-84e8-d394ebae4082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[97 12]\n",
      " [20 89]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.89      0.86       109\n",
      "         1.0       0.88      0.82      0.85       109\n",
      "\n",
      "    accuracy                           0.85       218\n",
      "   macro avg       0.86      0.85      0.85       218\n",
      "weighted avg       0.86      0.85      0.85       218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a4d868-c7d3-4c9e-ab78-c4b73cbf196a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e97db0a9-1a46-46ba-a41a-6cb4bb9e3c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "EvalPapertweetDF = pd.read_csv(\"premade_datasets/evaluation_paper.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e548833-bf71-46f4-9eed-f1262acaff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= EvalPapertweetDF['prep_text']\n",
    "y_test= EvalPapertweetDF['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "778e910d-1f8d-4d9d-989c-8e9c8b5deb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      USERNAME loovvee kindle2 dx cool 2 fantastic r...\n",
       "1              reading kindle2 love lee childs good read\n",
       "2               ok first assesment kindle2 fucking rocks\n",
       "3      USERNAME youll love kindle2 ive mine months ne...\n",
       "4             USERNAME fair enough kindle2 think perfect\n",
       "                             ...                        \n",
       "354    using latex lot typeset mathematics looks hideous\n",
       "355    note hate word hate pages hate latex said hate...\n",
       "356         ahh back real text editing environment latex\n",
       "357    trouble iran see hmm iran iran far away flocko...\n",
       "358    reading tweets coming iran whole thing terrify...\n",
       "Name: prep_text, Length: 359, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.apply(postProcessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7937807-7ccc-4751-840f-a9e75fc52244",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_indices = le.text_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "214dfc8f-8f7f-4c0f-b940-1d76b156377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_indices)\n",
    "y_pred = np.around(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4117a73-1e29-4d3d-8f4d-95b8dd5ff80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[123  54]\n",
      " [ 40 142]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72       177\n",
      "           1       0.72      0.78      0.75       182\n",
      "\n",
      "    accuracy                           0.74       359\n",
      "   macro avg       0.74      0.74      0.74       359\n",
      "weighted avg       0.74      0.74      0.74       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74568e0e-9585-47c5-bb1d-e052deb09b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d198166a-8164-46bd-b3e5-1e5464f48891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1b41a8b3-1c1e-41d2-b9a4-75bd28daf9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.weights\n",
    "\n",
    "with open(\"Bilstm_weights.pkl\", \"wb\") as f:\n",
    "    pickle.dump(weights, f)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
